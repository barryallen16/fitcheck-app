{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z-wbyainIywN"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os, re\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    import torch; v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
        "    xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
        "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "!pip install transformers==4.57.0\n",
        "!pip install --no-deps trl==0.22.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF2zZZiaI2bG"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!wget https://huggingface.co/datasets/barryallen16/fitcheck-annotate-dataset/resolve/main/fitcheck-dataset.zip\n",
        "!unzip fitcheck-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pG_CWPcRI36i"
      },
      "outputs": [],
      "source": [
        "!pip install qwen-vl-utils\n",
        "\n",
        "import torch\n",
        "from unsloth import FastVisionModel\n",
        "from qwen_vl_utils import process_vision_info\n",
        "import json\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"Loading Qwen2.5-VL with Unsloth optimization...\")\n",
        "\n",
        "# Load model with Unsloth - Much faster and more memory efficient!\n",
        "model, processor = FastVisionModel.from_pretrained(\n",
        "    # \"unsloth/Qwen2.5-VL-7B-Instruct-unsloth-bnb-4bit\",  # 7B model now fits in memory!\n",
        "    \"unsloth/Qwen3-VL-8B-Instruct-unsloth-bnb-4bit\",\n",
        "    # \"unsloth/Qwen3-VL-4B-Instruct-unsloth-bnb-4bit\",\n",
        "    load_in_4bit=True,\n",
        "    use_gradient_checkpointing=\"unsloth\",  # Unsloth's optimized checkpointing\n",
        ")\n",
        "\n",
        "# Enable inference mode (important for speed)\n",
        "FastVisionModel.for_inference(model)\n",
        "\n",
        "print(\"✅ Model loaded with Unsloth optimization!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DNoibgvI5db"
      },
      "outputs": [],
      "source": [
        "def classify_clothing_unsloth(image_path):\n",
        "    \"\"\"\n",
        "    Classify clothing using Unsloth-optimized Qwen2-VL model\n",
        "    Returns structured JSON metadata\n",
        "    \"\"\"\n",
        "\n",
        "    # Load image\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "    # Detailed prompt for Indian ethnic wear\n",
        "    prompt = \"\"\"Analyze this clothing item image. Focus only on the garment, ignore background and people.\n",
        "\n",
        "Provide detailed analysis in ONLY valid JSON format:\n",
        "\n",
        "{\n",
        "  \"specific_type\": \"detailed garment name (e.g., silk saree, embroidered kurti)\",\n",
        "  \"category\": \"exact category: kurta/kurti/palazzo/churidar/salwar/saree/lehenga/anarkali_suit/gown/dupatta/blouse/choli/dhoti_pants/skirt/shirt/t_shirt/jeans/trousers/crop_top/peplum_top/anarkali_top/cape/jacket/shawl/lehenga_set\",\n",
        "  \"color_primary\": \"dominant color with shade (e.g., deep maroon)\",\n",
        "  \"color_secondary\": [\"secondary color1\", \"secondary color2\"],\n",
        "  \"pattern\": \"design pattern (floral/paisley/solid/geometric/embroidery/prints)\",\n",
        "  \"material\": \"fabric type (silk/cotton/chiffon/georgette/denim/linen/crepe)\",\n",
        "  \"style\": \"traditional/contemporary/fusion/casual/formal/festive\",\n",
        "  \"occasions\": [\"wedding\", \"festival\", \"casual\", \"office\", \"party\", \"daily_wear\"],\n",
        "  \"weather\": [\"summer\", \"winter\", \"monsoon\", \"all_season\"],\n",
        "  \"formality\": \"casual/semi_formal/formal/festive\",\n",
        "  \"embellishments\": [\"embroidery\", \"sequins\", \"prints\", \"zari_work\", \"mirror_work\", \"plain\"],\n",
        "  \"gender\": \"male/female/unisex\",\n",
        "  \"fit\": \"loose/fitted/flowy/structured\"\n",
        "}\n",
        "\n",
        "Return ONLY the JSON object, no other text.\"\"\"\n",
        "\n",
        "    # Prepare messages\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"image\", \"image\": image},\n",
        "                {\"type\": \"text\", \"text\": prompt}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Prepare inputs\n",
        "    text = processor.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    image_inputs, video_inputs = process_vision_info(messages)\n",
        "\n",
        "    inputs = processor(\n",
        "        text=[text],\n",
        "        images=image_inputs,\n",
        "        videos=video_inputs,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    inputs = inputs.to(\"cuda\")\n",
        "\n",
        "    # Generate classification with Unsloth optimization\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=512,\n",
        "            temperature=0.3,\n",
        "            use_cache=True  # Unsloth optimizes KV cache\n",
        "        )\n",
        "\n",
        "    # Decode output\n",
        "    generated_ids_trimmed = [\n",
        "        out_ids[len(in_ids):]\n",
        "        for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
        "    ]\n",
        "\n",
        "    output_text = processor.batch_decode(\n",
        "        generated_ids_trimmed,\n",
        "        skip_special_tokens=True,\n",
        "        clean_up_tokenization_spaces=False\n",
        "    )[0]\n",
        "\n",
        "    # Parse JSON\n",
        "    try:\n",
        "        json_start = output_text.find('{')\n",
        "        json_end = output_text.rfind('}') + 1\n",
        "        json_str = output_text[json_start:json_end]\n",
        "        classification = json.loads(json_str)\n",
        "\n",
        "        # Check for template responses\n",
        "        if (classification.get(\"specific_type\") == \"detailed garment name (e.g., silk saree, embroidered kurti)\" or\n",
        "            classification.get(\"category\") == \"exact category: kurta/kurti/palazzo/churidar/salwar/saree/lehenga/anarkali_suit/gown/dupatta/blouse/choli/dhoti_pants/skirt/shirt/t_shirt/jeans/trousers/crop_top/peplum_top/anarkali_top/cape/jacket/shawl/lehenga_set\"):\n",
        "            print(f\"Warning: Template response for {image_path}\")\n",
        "            return None\n",
        "\n",
        "        return classification\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Warning: Could not parse JSON for {image_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing for {image_path}: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRMk7ZFAI7SI"
      },
      "outputs": [],
      "source": [
        "def process_indofashion_unsloth(base_path, output_csv=\"wardrobe_database_unsloth.csv\", output_jsonl=\"wardrobe_database_unsloth.jsonl\", batch_size=1):\n",
        "    \"\"\"\n",
        "    Process IndoFashion dataset with Unsloth optimization\n",
        "    Saves results in both CSV and JSONL formats\n",
        "    batch_size: Keep at 1 for image processing (models process images one at a time)\n",
        "    \"\"\"\n",
        "\n",
        "    results = []\n",
        "    image_files = []\n",
        "\n",
        "    # Collect all image paths\n",
        "    for folder_name in os.listdir(base_path):\n",
        "        folder_path = os.path.join(base_path, folder_name)\n",
        "        if os.path.isdir(folder_path):\n",
        "            for image_name in os.listdir(folder_path):\n",
        "                if image_name.lower().endswith(('.png', '.jpg', '.jpeg', '.webp')):\n",
        "                    image_files.append(os.path.join(folder_path, image_name))\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Processing {len(image_files)} images with Unsloth-optimized Qwen2-VL-7B\")\n",
        "    print(f\"Expected speedup: 2-5x faster than standard implementation\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Process with progress bar\n",
        "    for idx, image_path in enumerate(tqdm(image_files, desc=\"Classifying\")):\n",
        "        try:\n",
        "            classification = classify_clothing_unsloth(image_path)\n",
        "\n",
        "            if classification:\n",
        "                result_entry = {\n",
        "                    'item_id': f\"item_{idx:04d}\",\n",
        "                    'filename': os.path.basename(image_path),\n",
        "                    'image_path': image_path,\n",
        "                    'classification': classification\n",
        "                }\n",
        "                results.append(result_entry)\n",
        "\n",
        "            # Save checkpoint every 50 images\n",
        "            if (idx + 1) % 50 == 0:\n",
        "                temp_df = pd.DataFrame(results)\n",
        "                temp_df.to_csv(f\"checkpoint_unsloth_{idx+1}.csv\", index=False)\n",
        "\n",
        "                # Save JSONL checkpoint\n",
        "                with open(f\"checkpoint_unsloth_{idx+1}.jsonl\", 'w') as f:\n",
        "                    for item in results:\n",
        "                        f.write(json.dumps(item) + '\\n')\n",
        "\n",
        "                print(f\"\\n✅ Checkpoint saved: {idx+1} images processed\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n❌ Error processing {image_path}: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Calculate metrics\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    # Save final results\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "\n",
        "    # Save as JSONL\n",
        "    with open(output_jsonl, 'w') as f:\n",
        "        for item in results:\n",
        "            f.write(json.dumps(item) + '\\n')\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"✅ Processing Complete!\")\n",
        "    print(f\"✅ Processed: {len(results)} images\")\n",
        "    print(f\"✅ Time taken: {elapsed_time/60:.1f} minutes\")\n",
        "    if len(results) > 0:\n",
        "        print(f\"✅ Average: {elapsed_time/len(results):.2f} seconds per image\")\n",
        "    print(f\"✅ Saved to CSV: {output_csv}\")\n",
        "    print(f\"✅ Saved to JSONL: {output_jsonl}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aQHBvsOI8ij"
      },
      "outputs": [],
      "source": [
        "df = process_indofashion_unsloth(\"fitcheck-dataset/\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
